{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "vectorizer = CountVectorizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file\n",
    "def load(directory):\n",
    "    file_path = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".txt\"):\n",
    "            path = f\"{directory}/{file}\"\n",
    "            file_path.append(path)\n",
    "    \n",
    "    return file_path\n",
    "\n",
    "# split the dataset into training data and testing data\n",
    "def seperate_train_test(file_list, ratio=0.7):\n",
    "    train = random.sample(file_list, round(len(file_list)*ratio))\n",
    "    test = [f for f in file_list if f not in train]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def clean_email(f):\n",
    "    lines = f.readlines()\n",
    "    regex_list = [r\".*-.-.-.*\", r\"Subject:.*\", r\"subject :.*\", r\"from :.*\", r\"to :.*\", r\"cc :.*\"]            \n",
    "    for r in regex_list:\n",
    "        regex = re.compile(r)\n",
    "        lines = [l for l in lines if not regex.match(l)]\n",
    "    \n",
    "    tokenized_word = []\n",
    "    for l in lines:\n",
    "        tokenized_word += word_tokenize(l.strip().lower())\n",
    "                    \n",
    "    filtered_word = []\n",
    "    for w in tokenized_word:\n",
    "        if w not in stop_words:\n",
    "            filtered_word.append(w)\n",
    "\n",
    "    regex = re.compile(r\"\\w+[^\\d+]\")\n",
    "    filtered_word = [w for w in filtered_word if regex.match(w)]\n",
    "    \n",
    "    # stem\n",
    "    stemmed_words = []\n",
    "    for w in filtered_word:\n",
    "        stemmed_words.append(ps.stem(w))\n",
    "\n",
    "    return stemmed_words\n",
    "\n",
    "def dictionary(file_path):\n",
    "    words = []\n",
    "    for file in file_path:\n",
    "        try:\n",
    "            with open(file) as f:\n",
    "                stemmed_words = clean_email(f)\n",
    "                words += stemmed_words\n",
    "        except:\n",
    "                pass\n",
    "\n",
    "    dictionary = Counter(words)\n",
    "    dictionary = dictionary.most_common(3000)\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "def Euclidean_represent(file_path, cv):\n",
    "    content_list = []\n",
    "    for file in file_path:\n",
    "        try:\n",
    "            with open(file) as f:\n",
    "                stemmed_words = clean_email(f)\n",
    "                content = \"\"\n",
    "\n",
    "                for w in stemmed_words:\n",
    "                    content += f\"{w} \"\n",
    "\n",
    "            content_list.append(content)\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    vector = cv.fit_transform(content_list).toarray()\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## spam email classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory of ham and spam emails\n",
    "ham_directory = \"enron1/ham\"\n",
    "spam_directory = \"enron1/spam\"\n",
    "\n",
    "# load two kinds of emails\n",
    "ham_email = load(ham_directory)\n",
    "spam_email = load(spam_directory)\n",
    "\n",
    "# # of ham and spam emails\n",
    "n_ham = len(ham_email)\n",
    "n_spam = len(spam_email)\n",
    "\n",
    "# probability of ham and spam email\n",
    "ham_percent = n_ham /(n_ham + n_spam)\n",
    "spam_percent = n_spam /(n_ham + n_spam)\n",
    "\n",
    "# split data into train and test data\n",
    "ham_train, ham_test = seperate_train_test(ham_email)\n",
    "spam_train, spam_test = seperate_train_test(spam_email)\n",
    "\n",
    "# compute countvector \n",
    "ham_dictionary = dictionary(ham_train)\n",
    "spam_dictionary = dictionary(spam_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the total words in ham emails\n",
    "total_words = 0\n",
    "for key, value in ham_dictionary:\n",
    "    total_words += value\n",
    "\n",
    "# calculate frequency of each word in ham emails\n",
    "ham_word_p = {}    \n",
    "for key, value in ham_dictionary:\n",
    "    ham_word_p[key] = value / total_words *1000\n",
    "\n",
    "# claculate the total words in spam emails\n",
    "total_words = 0\n",
    "for key, value in spam_dictionary:\n",
    "    total_words += value\n",
    "\n",
    "# claculate the frequency of each word in spam emails\n",
    "spam_word_p = {}    \n",
    "for key, value in spam_dictionary:\n",
    "    spam_word_p[key] = value / total_words *1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for ham email\n",
    "result_ham = []\n",
    "for file in ham_test:\n",
    "    try:\n",
    "        with open(file) as f:\n",
    "            data = clean_email(f)\n",
    "            p_w_s = 1\n",
    "            p_w_h = 1\n",
    "            for w in data:\n",
    "                try:\n",
    "                    word_in_ham =  ham_word_p[w]\n",
    "                    word_in_spam =  spam_word_p[w]\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                p_w_h *= word_in_ham\n",
    "                p_w_s *= word_in_spam\n",
    "\n",
    "            p_spam = (p_w_s*spam_percent) / (p_w_s*spam_percent + p_w_h*ham_percent)\n",
    "            if p_spam >= 0.5:\n",
    "                result_ham.append(\"Spam\")\n",
    "            else:\n",
    "                result_ham.append(\"Ham\")\n",
    "    except:\n",
    "        print(\"open file failed\")\n",
    "        \n",
    "ham_class = result_ham.count(\"Ham\")\n",
    "ham_error = result_ham.count(\"Spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open file failed\n",
      "open file failed\n",
      "open file failed\n",
      "open file failed\n",
      "open file failed\n",
      "open file failed\n",
      "open file failed\n",
      "open file failed\n"
     ]
    }
   ],
   "source": [
    "# test for spam email\n",
    "result_spam = []\n",
    "for file in spam_test:\n",
    "    try:\n",
    "        with open(file) as f:\n",
    "            data = clean_email(f)\n",
    "            p_w_s = 1\n",
    "            p_w_h = 1\n",
    "            for w in data:\n",
    "                try:\n",
    "                    word_in_ham =  ham_word_p[w]\n",
    "                    word_in_spam =  spam_word_p[w]\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                p_w_h *= word_in_ham\n",
    "                p_w_s *= word_in_spam\n",
    "\n",
    "            p_spam = (p_w_s*spam_percent) / (p_w_s*spam_percent + p_w_h*ham_percent)\n",
    "            if p_spam >= 0.5:\n",
    "                result_spam.append(\"Spam\")\n",
    "            else:\n",
    "                result_spam.append(\"Ham\")\n",
    "    except:\n",
    "        print(\"open file failed\")\n",
    "        \n",
    "spam_class = result_spam.count(\"Spam\")\n",
    "spam_error = result_spam.count(\"Ham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Category\": [\"Ham\", \"Spam\"],\n",
    "                   \"Ham\": [result_ham.count(\"Ham\"), result_spam.count(\"Ham\")],\n",
    "                   \"Spam\": [result_ham.count(\"Spam\"), result_spam.count(\"Spam\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ham</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ham</th>\n",
       "      <td>975</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spam</th>\n",
       "      <td>40</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Ham  Spam\n",
       "Category           \n",
       "Ham       975   127\n",
       "Spam       40   402"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(\"Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
